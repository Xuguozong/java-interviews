### 1. 灵活的运用 tags 来过滤数据



### 2. 基于消息 key 来定位消息是否丢失

- 可以基于消息key来实现，比如通过下面的方式设置一个消息的key为订单id：message.setKeys(orderId)，这样这个消息就具备一个key了
- 接着这个消息到broker上，会基于key构建hash索引，这个hash索引就存放在IndexFile索引文件里
- 然后后续我们可以通过MQ提供的命令去根据key查询这个消息，类似下面这样：**mqadmin queryMsgByKey -n 127.0.0.1:9876 -t SCANRECORD -k orderId**



### 3. 消息零丢失方案的补充

> mq 集群挂了怎么办
>
> 一般假设MQ集群彻底崩溃了，你生产者就应该**把消息写入到本地磁盘文件里去进行持久化，或者是写入数据库里去暂存起来，等待MQ恢复之后，然后再把持久化的消息继续投递到MQ里去**



### 4. 提高消费者的吞吐量

- 如果消费的时候发现消费的比较慢，那么可以提高消费者的并行度，常见的就是部署更多的consumer机器
- 注意，你的**Topic的MessageQueue得是有对应的增加**，因为如果你的consumer机器有5台，然后MessageQueue只有4个，那么意味着有一个consumer机器是获取不到消息的
- 然后就是可以增加consumer的线程数量，可以设置consumer端的参数：consumeThreadMin、consumeThreadMax，这样一台consumer机器上的消费线程越多，消费的速度就越快
- 还可以开启消费者的批量消费功能，就是设置consumeMessageBatchMaxSize参数，他默认是1，但是你可以设置的多一些，那么一次就会交给你的回调函数一批消息给你来处理了，此时你可以通过SQL语句一次性批量处理一些数据，比如：update xxx set xxx where id in (xx,xx,xx)



### 5. 要不要消费历史消息

> 其实consumer是支持设置从哪里开始消费消息的，常见的有两种：一个是从Topic的第一条数据开始消费，一个是从最后一次消费过的消息之后开始消费。对应的是：CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET